---
title: 'Chapter 10: Lectal Lectometry'
author: "Stefano De Pascale"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    css: ./styles.css
    highlight: kate
    md_extensions: +bracketed_spans
    number_sections: yes
resource_files:
- safety_belt/safety_belt.freq3ppmi1.ttmx.meta
- safety_belt/safety_belt.freq3ppmi1.ttmx.npy
- safety_belt/safety_belt.tsne.tsv
- repayment/repayment.tsne.tsv
- repayment/repayment.freq3ppmi1.ttmx.npy
- repayment/repayment.freq3ppmi1.ttmx.meta
- appreciation/appreciation.freq3ppmi1.ttmx.meta
- appreciation/appreciation.freq3ppmi1.ttmx.npy
- appreciation/appreciation.tsne.tsv
- dip/dip.freq3ppmi1.ttmx.meta
- dip/dip.freq3ppmi1.ttmx.npy
- dip/dip.tsne.tsv
- keyboard/keyboard.freq3ppmi1.ttmx.meta
- keyboard/keyboard.freq3ppmi1.ttmx.npy
- keyboard/keyboard.tsne.tsv
- chat/chat.freq3ppmi1.ttmx.meta
- chat/chat.freq3ppmi1.ttmx.npy
- chat/chat.tsne.tsv
- opening_hours/opening_hours.freq3ppmi1.ttmx.meta
- opening_hours/opening_hours.freq3ppmi1.ttmx.npy
- opening_hours/opening_hours.tsne.tsv
runtime: shiny
csl: ./apa.csl
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(shiny)
library(tippy)
library(knitr)
library(rmdformats)
library(kfigr)
library(kableExtra)
library(tidyverse)
library(pander)
library(DT)
library(cluster)

library(RcppCNPy)
library(RColorBrewer)
library(rjson)
library(ggplot2)
library(plotly)
library(dplyr)
library(dendextend, quietly=T)
library(reshape2)
library(dynamicTreeCut)
library(entropy)
library(AMR)
library(pwr)
library(shinydashboard)

WORKFOLDER <- "C:/Users/u0102617/Box/GitHub/StefanoDePascale.github.io/lectometry"

d.clust <- read.csv("concepts-measures-withclusters.txt", header=T, sep=" ", check.names = F)
d.noclust <- read.csv("concepts-measures-withoutclusters.txt", header=T, sep=" ", check.names = F)

```
# Weighting strategies for lectometric analyses

## The dataset: selection of concepts

```{r, include=FALSE}
concepts1 <- c("safety belt", "ecstasy", "wedding", "display window", "apartment building", "chat", "religion", "appreciation", "stress", "individuality")
concepts2 <- c("reflection", "demolition", "keyboard", "dip", "repayment", "stronghold", "nail", "sex", "palm tree", "pitch")
concepts3 <- c("peace talks", "submarine", "retaliation", "town center", "pity", "allegation", "tour operator", "filmmaker", "suspicion", "draw")
concepts4 <- c("commuter", "opening hours", "lack of space"," electoral district", "cash", "scriptwriter", "voyage of discovery", "amusement park", "database", "nuclear reactor")
```

The set of analyzed concepts were all selected from the lexical variables generated by the enhanced Clustering-by-Committee algorithm (henceforth CBC 2.0). In order to qualify for selection we required the lexical variable to match in exact terms (i.e. in composition and in size) with the Dutch WordNet synset that is incorporated in Cornetto 1.3 (the release available in R2d2). We can distinguish four subgroups in this set of concepts, based on 1) the potential presence of polysemy in one its constituent lexicalisations and 2) the number of lexicalisations:

* 10 concepts with 3 near-synonyms, one of which appears in more than 1 synset, and is therefore considered potentially polysemous. These concepts are: <span style="text-transform: lowercase; font-variant: small-caps;">`r paste0("[",concepts1,"](#",sub(" ","",concepts1),")", collapse = ", ")`</span>. They were chosen among the 16 exact matches with the aforementioned properties, and in addition by avoiding the extremely frequent concepts (more than 10000 tokens, before disambiguation).

* 10 concepts with 2 near-synonyms, one of which appears in more than 1 synset, and is therefore considered potentially polysemous. These concepts are: <span style="text-transform: lowercase; font-variant: small-caps;">`r paste0("[",concepts2,"](#",sub(" ","",concepts2),")", collapse = ", ")`</span>. As the exact matches with 2 near-synonyms constitute a sizeable set in the CBC output (450), we selected concepts such that A) they would have a total frequency lower than 1500, B) their set would vary along a large range of external uniformity values (actually from 0.5 to 0.9) and C) their polysemy structure was expected to emerge from the token-based vector spaces.

* 11 concepts with 3 near-synonyms, of which none appears in more than 1 synsets. Therefore, we do not expect any of these variants to show a traditionally-defined polysemous  `r tippy("structure", tooltip="<sup>1</sup>This does not mean that these variants cannot display other, more or less marked and unexpected semasiological variation of other sorts, for instance, oblique construal, or topic-specific readings", theme="light-border", arrow=TRUE)`^1^. These concepts are: <span style="text-transform: lowercase; font-variant: small-caps;">`r paste0("[",concepts3,"](#",sub(" ","",concepts3),")", collapse = ", ")`</span>. To these initial 10 concepts we added an 11th one, namely <span style="text-transform: lowercase; font-variant: small-caps;">[convict](#convict)</span>. They were chosen among the 16 exact matches with the aforementioned properties.

* 11 concepts with 2 near-synonyms, of which none appears in more than 1 synsets. These concepts are: <span style="text-transform: lowercase; font-variant: small-caps;">`r paste0("[",concepts4,"](#",sub(" ","",concepts4),")", collapse = ", ")`</span>. To these initial 10 concepts we added an 11th one, namely <span style="text-transform: lowercase; font-variant: small-caps;">[living room](#livingroom)</span>. As the exact matches with 2 near-synonyms constitute a sizeable set in the CBC output (450), we selected concepts such that A) they would have a total frequency lower than 1500, B) their set would vary along the full spectrum of external uniformity values (actually from 0.1 to 0.9) and C) their polysemy structure was expected to emerge from the token-based vector spaces.

## Weighting and filtering of concepts (with or without cluster analysis)

Different concepts can contribute in different ways to the aggregated lectal distances between the national varieties of Dutch, that is, Belgian Dutch and Netherlandic Dutch. In the <span class="reference">Geeraerts, Grondelaers, & Speelman (1999)</span> monograph, the procedure for determining a differential contribution of concepts consisted of three steps:

* first, to establish whether the lectal profiles for a given concept are significantly different,
* second, to include such differences in the aggregate calculation over concepts when they are significant, and to include the nonsignificant cases as exhibiting 100% uniformity or equivalently 0 distance (this means, in other words, that the significance test is precisely that: a test of the hypothesis that the observed differences represent ‘real’ differences),
* third, when aggregating over different concepts, to give a different weight to the uniformity measure of given concept on the basis of its relative frequency.

The original 1999 method, and its subsequent refinements, would apply to concepts in their entirety, often after manual semantic disambiguation of the tokens had been carried out on the concept under scrutiny. Applying this same procedure to clusters within a concept would mean the following:

* first, to establish whether the cluster-based lexical profiles of a given concept are significantly different;
* second, to treat non-significant clusters as exhibiting 100% uniformity or equivalently 0 distance and to treat significantly different clusters as exhibiting ‘real’ differences;
* third, to aggregate over the uniformity measures of different clusters weighted by the relative frequency of clusters.

The first and second parts of this method thus essential relies on **stastical significance as a filter mechanism**. When we approach the comparison of profiles within the statistical framework of hypothesis testing, we can consider the frequencies in a profile to be the sample of a random variable that has a multinomial distribution. The null hypothesis of such test states that both samples are drawn from the same population: the distribution of the synonyms does not differ between the national varieties, and, based on that, the inference would be that the national varieties cannot be considered different linguistic varieties. The alternative hypothesis consists of claiming that the onomasiological profiles do differ, and that we are dealing with separate linguistic varieties. A statistical test can then calculate a probability (i.e. the p-value) that quantifies how likely it is to find the observed differences in distribution of near-synonyms, given that the null hypothesis of no lectal differences holds. One rejects the null hypothesis and accepts the alternative hypothesis when this probability is lower than the customary significance level α = 0.05, which is the probability that we have chosen under which we reject the null hypothesis. The strength of statistical testing approach is that it is sensitive to how much evidence there is for the assumption that there actually is an underlying difference between the two profiles, so that we can avoid overrating distances that are not based on a substantial amount of tokens. 

<div class="infobox", font-size="10px">
  Statistical significance can also be employed in two other different ways: as a <strong>weighting measure</strong> or as a <strong>distance metric</strong> by itself. In the first case, instead of using the the p-value as a cut-off point for filtering, one could weight (i.e. multiply) the uniformity or distance by 1 - p-value, such that overall significantly different onomasiological profiles could have a larger impact on the aggregate lectal distance between Netherlandic Dutch and Belgian Dutch. This approach was suggested in <span class="reference">Speelman, Grondelaers, & Geeraerts (2003: 366)</span> and explored in <span class="reference">Ruette (2012: 93)</span>. The influence of this type of weighting was nevertheless considered to be minimal. In the second case the p-value obtained after the statistical significance test would be used directly as a distance metric. This option was investigated in <span class="reference">Speelman, Grondelaers, & Geeraerts (2003)</span>. In this report we will limit ourselves to using statistical significance as a filter mechanism. 
</div>

Two statistical tests are going to be used in this respect: the **Log Likelihood Ratio test** and **Fisher's Exact Test**. If the resulting p-value of such a test is lower than the customary significance level α = 0.05, the null hypothesis of the absence of difference between profiles is rejected, and the observed City Block distance can be safely assumed to show a real difference between the regiolects. If the p-value is higher than the α-level, the City Block distance is set to 0, no lectal distance, which corresponds to accepting the null hypothesis of no difference between the onomasiological profiles. Although the Log Likelihood Ratio test, and in general hypothesis testing, was precisely meant to avoid taking for granted lectal distances based on low-frequent profiles, it is a test that can still suffer from sparse data. Fisher's Exact Test is known to suffer less from data sparseness in the cells of the contigency tables, and should therefore be even more reliable than the LLR for low-frequent profiles.  

The weakness of this approach is that statistical significance can be manipulated by simply increasing the sample size of one or both onomasiological profiles in the comparison. Being dependent on sample size, the test will exaggerate the weight of frequent concepts, regardless of the lectal distance (in other words, the effect size) and downplay the weight of infrequent concepts (this criticism was already raised by <span class="reference">Ruette (2012: 93)</span>. 

To overcome this weakness, we can rely on **statistical power as an (additional) filter mechanism**. The statistical power of one of the binary hypothesis tests introduced above indicates, loosely speaking, the confidence we have that with the available data we are able to find a 'real' difference between profiles, given the presence of such a 'real' difference (i.e given that we have rejected the null hypothesis and accepted the alternative hypothesis). The power of a test is directly related to the type II-error probability β. The β-level of a test indicates the probability (we can tolerate) of falsely rejecting the true alternative hypothesis, and accepting the false null hypothesis. The corresponding statistical power of a test is 1 − β, and ranges from 0 to 1. Keeping the type II-error probability low means increasing the power of a study. Just as with the significance level α (which is the probability we can tolerate of falsely rejecting the true null hypothesis and accepting the false alternative hypothesis, that is, a the Type I-error), a threshold can be chosen in advance by the researcher, and the minimal power of a test this is usually set to 0.80. The computation of the statistical power depends on a combination of the significance level (α-level), the sample size (i.e. the total frequency of the compared profiles) and the effect size (i.e. the lectal distance, quantified as Cramèr's V). 

It is indeed possible to observe a significant difference in profiles between regiolects (where the p-value is lower than the significance level α), but that significance might be either due to the sample size (with the idea that the larger the sample size, the easier it will be to obtain a significant effect, regardless of the magnitude of the effect) or  to a genuine, true difference between the regiolects. A power analysis is often conducted prior to the hypothesis stest, in order to calculate the minimum sample size required for observing an effect of a given size. But power can be estimated even post-hoc after a test has been conducted. Using statistical power as a filter mechanism then boils down to a similar procedure as with statistical significance: if the 1 - β is lower than the 0.80, meaning there is insufficient power to accept the alternative hypothesis, the City Block distance is set to 0, no lectal distance, which corresponds to accepting the null hypothesis of no difference between the onomasiological profiles.

<div class="infobox", style="float:none; font-size:16px; color:red; border: 4px solid red; width: 50%; margin: auto">
<strong>WARNING!</strong> It is questionable whether this observed power can be a useful additional filter mechanism, or whether it is simply an unsound concept. I leave it up here for discussion! 
</div>

### Baseline scenario: lectal distances without semantic control

Before we venture in the calculation of lectal distances based on subregiones/clusters within the semantic space defined by a concept's lexicalizations, it might instructive to look at lectal distances generated without any regard for the semantic structure of the lexemes involved. Lectal distances based on all retrieved tokens of the lexemes can then act as useful reference to which we can compare lectal distances obtained with more attention for the semantic reality behind those tokens.

It is evident that these calculations are flawed, because we know for sure that they are flawed: there has been no correction or selection of the tokens whatsoever. Although they have a rather limited use for description, they can showcase how the applying the different filters (significance based on LLR, based on Fisher's Exact Test, based on power) yield different outcomes, and how the real analyses will/might look like. 

```{r, echo=FALSE}
d.concept <- d.noclust %>% 
  select('concept','distance_cityblock', 'filter.fisher','filter.llr','filter.power') %>%
  mutate(distance_cityblock*filter.llr,
         distance_cityblock*filter.fisher,
         distance_cityblock*filter.power) %>%
  select(-starts_with('filter'))

colnames(d.concept) <- c("Concept", "No filter", "LLR filter", "Fisher filter","power filter")

# kable(d.concept, caption= "No clusters", digits = 3, escape = FALSE) %>% 
#   kable_styling(full_width = T) %>%
#   add_header_above(c("","City Block"=4)) %>%
#   column_spec(c(1:5), extra_css = "vertical-align:middle;")

sketch = htmltools::withTags(table(
  class = 'display',
  thead(
    tr(
      th(rowspan = 2, 'Concepts'),
      th(colspan = 4, 'City Block'),
    ),
    tr(
      lapply(rep(c("No filter", "LLR filter", "Fisher filter","power filter"), 1), th)
    )
  )
))

d.concept$Concept <- str_replace_all(d.concept$Concept,"_"," ")

datatable(d.concept, rownames=FALSE, container = sketch, filter="top") %>%
  formatStyle('Concept', c('LLR filter','power filter'), target="row", 
              fontVariant="small-caps", 
              fontSize="16px", 
              fontWeight="bold", color=styleEqual(0, 'red')) %>%
  formatStyle('No filter', background = styleColorBar(d.concept$`No filter`, '#6699FF'))

```

The third part in the calculation of lectal distances involves takes place not at the level of individual concepts, like the filter procedure did, but at the aggregated level. It has by consequence an impact on how the final lectal distance will look like. This part consists in the **weighting of concepts by the relative concept frequency in the dataset under scrutiny**. In <span class="reference">Ruette (2012: 93)</span>

The aggregated distances 
$$D_{no-filter}(BE_{all},NL_{all}) =  `r mean(d.concept[['No filter']])`$$
$$D_{llr/fisher-filter}(BE_{all},NL_{all}) =  `r mean(d.concept[['LLR filter']])`$$
$$D_{power-filter}(BE_{all},NL_{all}) =  `r mean(d.concept[['power filter']])`$$



The main finding resulting from the table above is that for the vast majority of concepts (36 out of 42 to be precise), the application of filters does not affect the lectal distances. For almost all concepts the hypothesis tests, be it LLR or Fisher's Exact test, report significantly different distributions; therefore most City Block distances are kept. The concepts for which the tests cannot reject the null hypothesis of no lectal difference, and thus receive a distance of 0, are <span style="text-transform: lowercase; font-variant: small-caps;">[nuclear reactor](#nuclearreactor), [suspicion](#suspicion) and [religion](#religion)</span>. As these are all concepts that with the lowest lectal distances in the dataset, we can assume that the null hypothesis of no lectal difference could not be rejected because effectively there does not seem to be a difference between the profiles. 

The filter based on statistical power sets the distance of another three concepts to 0: <span style="text-transform: lowercase; font-variant: small-caps;">[pitch](#pitch), [retaliation](#retaliation) and [ecstasy](#ecstasy)</span>. These are the concepts with the next three lowest lectal distances in the database. It is important to note that the total concept frequency for all concepts is 1000, since we set a maximum threshold during their retrieval (justified by the purpose of the Frontiers in AI article). The third step in the lectometric procedure, that is, the relative weight of the concept, is therefore superfluous on this dataset in this case. Given the fixed values for the total sample size (i.e. 1000) and the significance level, the power of the test seems to depend solely on the effect size (i.e. Cramer's V). 

It is surprising to see that the concept <span style="text-transform: lowercase; font-variant: small-caps;">[convict](#convict)</span> keeps his City Block distance after the power filter, even though this distance is lower than the lectal distance of <span style="text-transform: lowercase; font-variant: small-caps;">[ecstasy](#ecstasy)</span>. The Cramèr's V value is slightly higher (0.095 vs. 0.094), but is lower than that same value for<span style="text-transform: lowercase; font-variant: small-caps;">[retaliation](#retaliation)</span> (0.097). It is not very clear what is happening here!

### Lectal distances with semantic control: cluster analysis

#### safety belt {#safetybelt}

```{r, safety_belt, echo=FALSE}
# change path for retrieving dataframe of semantic nMDS- or tSNE-coordinates and metadata information

conceptName = "safety_belt"

# the UI bit:
fluidPage(
        box(status = "primary", solidHeader = TRUE,
        fluidRow(width=4,
            column(width=4, selectInput(inputId = paste0("color_coding_",conceptName),
                        label = "Color coding:",
                        choices = c("cluster","clusterpam","lemma","country"),
                        multiple = TRUE)),
            column(width=4, selectInput(inputId = paste0("shape_coding_",conceptName),
                        label = "Shape coding:",
                        choices = c("cluster","clusterpam","lemma","country"),
                        multiple = TRUE))
          )
        # fluidRow(
        #     column(width=12,plotlyOutput("myplot"))
        # )
    )
  )

`+.uneval` <- function(a,b) {
    `class<-`(modifyList(a,b), "uneval")
}

# the server bit:
renderPlotly({
  
  conceptName = "safety_belt"

dynamic_method = FALSE
clustering = TRUE
suffix = ".freq3ppmi1"
 
# open and store dataframe

d.tsv <- read.csv(paste0(conceptName,"/",conceptName,".tsne.tsv"),header=T, sep="\t", quote="", check.names = F, encoding="UTF8")

# target token in bold face
d.tsv$`_ctxt.model` <- gsub("<span(<br>|\\s)class='target'>([^<]+)</span>","<b>\\2</b>", d.tsv$`_ctxt.model`)
# significant context words in italics
d.tsv$`_ctxt.model` <- gsub("<u>([^<]+)</u>", "<i>\\1</i>", d.tsv$`_ctxt.model`)
# remove "small font" tags for context words outside of context window
d.tsv$`_ctxt.model` <- gsub("</?small>", "", d.tsv$`_ctxt.model`)
# insert line breaks every 50 characters in the concordance of a token
# (in order to avoid long stretches of text in the visualization)
d.tsv$`_ctxt.model` <- gsub("(.{50,}?)\\s", "\\1<br>", d.tsv$`_ctxt.model`)
d.tsv$text <- d.tsv$`_ctxt.model`

rownames(d.tsv) <- d.tsv$`_id`

if (clustering == TRUE) {
  rows_matrices <- list()
  d <- npyLoad(paste0(conceptName,"/",conceptName,suffix,".ttmx.npy"))
  tokenids <- fromJSON(file = paste0(conceptName,"/",conceptName,suffix,".ttmx.meta"))
  colnames(d) <- tokenids$row_items
  rownames(d) <- tokenids$row_items
  
  dst <- as.dist(as.matrix(d)) # 1000 randomly selected tokens
  
  hcl <- hclust(as.dist(dst), method="ward.D2")
  dend <- as.dendrogram(hcl)
  
  pamcl <- pam(dst, k=5)
  
  if (dynamic_method == TRUE) {
    clusters <- cutreeDynamic(hcl, distM = dst, method = "tree")
    
    clusters <- clusters[order.dendrogram(dend)]
    clusters_numbers <- unique(clusters) - (0 %in% clusters)
    n_clusters <- length(clusters_numbers)
    
    clusters_final <- cutree(dend, k=n_clusters, order_clusters_as_data = FALSE)
    clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
    clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
    
    variant_types <- unique(gsub("^([^/]+)/.+","\\1",clusters.df$tokens,perl=T))
    lect_types <- c("BE-Du", "NL-Du")
    
    } else {
      clusters_final <- cutree(dend, k=5, order_clusters_as_data = FALSE)
      clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
      clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
      
    }
  
  dpamcl <- data.frame(cluster=pamcl$clustering)
  d.tsv$clusterpam <- dpamcl[rownames(d.tsv),"cluster"]
  d.tsv$clusterpam <- as.factor(as.character(d.tsv$clusterpam))
  
  d.tsv$cluster <- clusters.df[rownames(d.tsv), "cluster"]
  d.tsv$cluster <- as.factor(as.character(d.tsv$cluster))

  set.seed(1990); shape_manual <- sample(c(3,2,16,7,8), length(levels(d.tsv$cluster)))
  set.seed(1990); color_manual <- sample(c("firebrick2","limegreen","royalblue2","grey30","gold"), length(levels(d.tsv$cluster)))
  }

         p <- ggplot(d.tsv, aes(model.x,model.y)) +
           geom_point(aes_string(colour=input[[paste0("color_coding_",conceptName)]], 
                                 shape=input[[paste0("shape_coding_",conceptName)]]) +  
                        aes(text=paste("<b>Country</b>: ", d.tsv$country,"|",
                                       "<b>Word</b>: ", d.tsv$lemma,"|",
                                       "<b>Newspaper</b>: ", d.tsv$newspaper,
                                       "</br><b>Token</b>: ", d.tsv$`_id`,
                                       "</br></br><b>Context</b>: ", d.tsv$text
                                       )
                            )
                      ) + 
           scale_color_manual(values = color_manual) +
           scale_shape_manual(values = shape_manual) +
           theme_bw() 
         
         ggplotly(p, tooltip = "text", opacity=0.5) %>%
           layout(hoverlabel = list(bgcolor=c("rgb(255,255,204"), align="left"),
                  xaxis = list(scaleanchor = "y", scaleratio = 1),
                  dragmode =  "select")
         })

```
```{r, anchor = "Table", echo=FALSE}

l <- "safety_belt"
d.concept <- d.clust %>% 
  filter(concept == l) %>%
  select('cluster', 'distance_cityblock', 'filter.fisher','filter.llr','filter.power') %>%
  mutate(distance_cityblock*filter.llr,
         distance_cityblock*filter.fisher,
         distance_cityblock*filter.power) %>%
  select(-starts_with('filter'))

d.concept$semantics <- c(
"<i>riem</i> as 'oar/paddle', more specifically in the idiom <i>'roeien met de riemen die men heeft'</i>",
"<ul class='intable'><li><i>riem</i> as 'shoulder/waistbelt', more specifically in the idiom <i>'een hart onder de riem steken'</i></li><li><i>gordel</i> as 'belt', more specifically in the idioms <i>'een slag/stoot onder de gordel'</i></li></ul>",
"<span class='concept'>safety belt</span>",
"<ul class='intable'><li><i>gordel</i> as 'waistbelt', often as 'judo/karate belt'</li><li><i>riem</i> as 'waistbelt', often in fashion context (with <i>leren</i>)</li></ul>",
"<ul class='intable'><li><i>gordel</i> as 'encircling area' (e.g. <i>groene gordel</i>) and as <span class='concept'>safety belt</span></li><li><i>riem</i> as 'waistbelt', more specifically in the idiom <i>'de riem afleggen'</i> and in fashion context</li></ul>")

tableList <- list()
for (cl in 1:5) {
  
  freqs <- d.clust %>% 
    filter(concept == l & cluster == cl) %>%
    select(starts_with('var'))
  
  freqs.m <- matrix(freqs %>% select(-variants), ncol=2)
  freqs.m <- freqs.m[rowSums(is.na(freqs.m)) != ncol(freqs.m), ]
  
  variants <- as.character(freqs$variants)
  
  colnames(freqs.m) <- c("BE","NL")
  rownames(freqs.m) <- str_split(variants,"/")[[1]]
  
  tableList[[cl]] <- kable(freqs.m)
}

d.concept <- d.concept %>% add_column(table=tableList, .before="distance_cityblock")


colnames(d.concept) <- c("Cluster", "Contigency table", "No filter", "LLR filter", "Fisher filter","power filter","Semantics")

kable(d.concept, caption= str_c("Definitions of '", l, "'."), digits = 3, escape = FALSE) %>% 
  kable_styling(full_width = T) %>%
  add_header_above(c("","","City Block"=4,"")) %>%
  column_spec(c(1:7), extra_css = "vertical-align:middle;")
```

#### repayment {#repayment}

```{r, repayment, echo=FALSE}

conceptName = "repayment"

fluidPage(
        box(status = "primary", solidHeader = TRUE,
        fluidRow(width=4,
            column(width=4, selectInput(inputId = paste0("color_coding_",conceptName),
                        label = "Color coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
            column(width=4, selectInput(inputId = paste0("color_coding_",conceptName),
                        label = "Shape coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
          )
    )
  )

`+.uneval` <- function(a,b) {
    `class<-`(modifyList(a,b), "uneval")
}

renderPlotly({
  
  conceptName = "repayment"

  dynamic_method = FALSE
  clustering = TRUE
  suffix = ".freq3ppmi1"
   
  # open and store dataframe
  
  d.tsv <- read.csv(paste0(conceptName,"/",conceptName,".tsne.tsv"),header=T, sep="\t", quote="", check.names = F, encoding="UTF8")
  
  # target token in bold face
  d.tsv$`_ctxt.model` <- gsub("<span(<br>|\\s)class='target'>([^<]+)</span>","<b>\\2</b>", d.tsv$`_ctxt.model`)
  # significant context words in italics
  d.tsv$`_ctxt.model` <- gsub("<u>([^<]+)</u>", "<i>\\1</i>", d.tsv$`_ctxt.model`)
  # remove "small font" tags for context words outside of context window
  d.tsv$`_ctxt.model` <- gsub("</?small>", "", d.tsv$`_ctxt.model`)
  # insert line breaks every 50 characters in the concordance of a token
  # (in order to avoid long stretches of text in the visualization)
  d.tsv$`_ctxt.model` <- gsub("(.{50,}?)\\s", "\\1<br>", d.tsv$`_ctxt.model`)
  d.tsv$text <- d.tsv$`_ctxt.model`
  
  rownames(d.tsv) <- d.tsv$`_id`
  
  if (clustering == TRUE) {
    rows_matrices <- list()
    d <- npyLoad(paste0(conceptName,"/",conceptName,suffix,".ttmx.npy"))
    tokenids <- fromJSON(file = paste0(conceptName,"/",conceptName,suffix,".ttmx.meta"))
    colnames(d) <- tokenids$row_items
    rownames(d) <- tokenids$row_items
    
    dst <- as.dist(as.matrix(d)) # 1000 randomly selected tokens
    
    hcl <- hclust(as.dist(dst), method="ward.D2")
    dend <- as.dendrogram(hcl)
    
    if (dynamic_method == TRUE) {
      clusters <- cutreeDynamic(hcl, distM = dst, method = "tree")
      
      clusters <- clusters[order.dendrogram(dend)]
      clusters_numbers <- unique(clusters) - (0 %in% clusters)
      n_clusters <- length(clusters_numbers)
      
      clusters_final <- cutree(dend, k=n_clusters, order_clusters_as_data = FALSE)
      clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
      clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
      
      variant_types <- unique(gsub("^([^/]+)/.+","\\1",clusters.df$tokens,perl=T))
      lect_types <- c("BE-Du", "NL-Du")
      
      } else {
        clusters_final <- cutree(dend, k=5, order_clusters_as_data = FALSE)
        clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
        clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
        
        }
    
    d.tsv$cluster <- clusters.df[rownames(d.tsv), "cluster"]
    d.tsv$cluster <- as.factor(as.character(d.tsv$cluster))
  
    set.seed(1990); shape_manual <- sample(c(3,2,16,7,8), length(levels(d.tsv$cluster)))
    set.seed(1990); color_manual <- sample(c("firebrick2","limegreen","royalblue2","grey30","gold"), length(levels(d.tsv$cluster)))
    }
  
           p <- ggplot(d.tsv, aes(model.x,model.y)) +
             geom_point(aes_string(colour=input[[paste0("color_coding_",conceptName)]], 
                                   shape=input[[paste0("shape_coding_",conceptName)]]) +  
                          aes(text=paste("<b>Country</b>: ", d.tsv$country,"|",
                                         "<b>Word</b>: ", d.tsv$lemma,"|",
                                         "<b>Newspaper</b>: ", d.tsv$newspaper,
                                         "</br><b>Token</b>: ", d.tsv$`_id`,
                                         "</br></br><b>Context</b>: ", d.tsv$text
                                         )
                              )
                        ) + 
             scale_color_manual(values = color_manual) +
             scale_shape_manual(values = shape_manual) +
             theme_bw() 
           
           ggplotly(p, tooltip = "text", opacity=0.5) %>%
             layout(hoverlabel = list(bgcolor=c("rgb(255,255,204"), align="left"),
                    xaxis = list(scaleanchor = "y", scaleratio = 1),
                    dragmode =  "select")
         })

```
```{r, anchor = "Table", echo=FALSE}
l <- "repayment"
d.concept <- d.clust %>% 
  filter(concept == l) %>%
  select('cluster', 'distance_cityblock', 'filter.fisher','filter.llr','filter.power') %>%
  mutate(distance_cityblock*filter.llr,
         distance_cityblock*filter.fisher,
         distance_cityblock*filter.power) %>%
  select(-starts_with('filter'))

d.concept$semantics <- c(
"<i>aflossing</i> as ‘changing of the guard [mostly figurative]’ (<i>aflossing van de wacht</i>)",
"<i>aflossing</i> as <span class='concept'>repayment</span>, more specifically in the context of government debts (<i>aflossing van de staatschuld</i>)",
"<span class='concept'>repayment</span>, more specifically in the context of private debts, loans and mortgages (<i>aflossing/afbetaling van de schuld/lening/hypotheek</i>",
"<i>aflossing</i> as ‘relay race’",
"<ul class='intable'><li>‘installment/repayment’ (maandelijkse aflossingen/afbetalingen)</li>
<li><i>afbetaling</i> as ‘on credit’ (<i>kopen op afbetaling</i>)</li></ul>"
)

tableList <- list()
for (cl in 1:5) {
  
  freqs <- d.clust %>% 
    filter(concept == l & cluster == cl) %>%
    select(starts_with('var'))
  
  freqs.m <- matrix(freqs %>% select(-variants), ncol=2)
  freqs.m <- freqs.m[rowSums(is.na(freqs.m)) != ncol(freqs.m), ]
  
  variants <- as.character(freqs$variants)
  
  colnames(freqs.m) <- c("BE","NL")
  rownames(freqs.m) <- str_split(variants,"/")[[1]]
  
  tableList[[cl]] <- kable(freqs.m)
}

d.concept <- d.concept %>% add_column(table=tableList, .before="distance_cityblock")


colnames(d.concept) <- c("Cluster", "Contigency table", "No filter", "LLR filter", "Fisher filter","power filter","Semantics")

kable(d.concept, caption= str_c("Definitions of '", l, "'."), digits = 3, escape = FALSE) %>% 
  kable_styling(full_width = T) %>%
  add_header_above(c("","","City Block"=4,"")) %>%
  column_spec(c(1:7), extra_css = "vertical-align:middle;")
```

#### appreciation {#appreciation}

```{r, appreciation, echo=FALSE}
# change path for retrieving dataframe of semantic nMDS- or tSNE-coordinates and metadata information

conceptName = "appreciation"

# the UI bit:
fluidPage(
        box(status = "primary", solidHeader = TRUE,
        fluidRow(width=4,
            column(width=4, selectInput(inputId = paste0("color_coding_",conceptName),
                        label = "Color coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
            column(width=4, selectInput(inputId = paste0("shape_coding_",conceptName),
                        label = "Shape coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
          )
        # fluidRow(
        #     column(width=12,plotlyOutput("myplot"))
        # )
    )
  )

`+.uneval` <- function(a,b) {
    `class<-`(modifyList(a,b), "uneval")
}

# the server bit:
renderPlotly({
  
  conceptName = "appreciation"

dynamic_method = FALSE
clustering = TRUE
suffix = ".freq3ppmi1"
 
# open and store dataframe

d.tsv <- read.csv(paste0(conceptName,"/",conceptName,".tsne.tsv"),header=T, sep="\t", quote="", check.names = F, encoding="UTF8")

# target token in bold face
d.tsv$`_ctxt.model` <- gsub("<span(<br>|\\s)class='target'>([^<]+)</span>","<b>\\2</b>", d.tsv$`_ctxt.model`)
# significant context words in italics
d.tsv$`_ctxt.model` <- gsub("<u>([^<]+)</u>", "<i>\\1</i>", d.tsv$`_ctxt.model`)
# remove "small font" tags for context words outside of context window
d.tsv$`_ctxt.model` <- gsub("</?small>", "", d.tsv$`_ctxt.model`)
# insert line breaks every 50 characters in the concordance of a token
# (in order to avoid long stretches of text in the visualization)
d.tsv$`_ctxt.model` <- gsub("(.{50,}?)\\s", "\\1<br>", d.tsv$`_ctxt.model`)
d.tsv$text <- d.tsv$`_ctxt.model`

rownames(d.tsv) <- d.tsv$`_id`

if (clustering == TRUE) {
  rows_matrices <- list()
  d <- npyLoad(paste0(conceptName,"/",conceptName,suffix,".ttmx.npy"))
  tokenids <- fromJSON(file = paste0(conceptName,"/",conceptName,suffix,".ttmx.meta"))
  colnames(d) <- tokenids$row_items
  rownames(d) <- tokenids$row_items
  
  dst <- as.dist(as.matrix(d)) # 1000 randomly selected tokens
  
  hcl <- hclust(as.dist(dst), method="ward.D2")
  dend <- as.dendrogram(hcl)
  
  if (dynamic_method == TRUE) {
    clusters <- cutreeDynamic(hcl, distM = dst, method = "tree")
    
    clusters <- clusters[order.dendrogram(dend)]
    clusters_numbers <- unique(clusters) - (0 %in% clusters)
    n_clusters <- length(clusters_numbers)
    
    clusters_final <- cutree(dend, k=n_clusters, order_clusters_as_data = FALSE)
    clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
    clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
    
    variant_types <- unique(gsub("^([^/]+)/.+","\\1",clusters.df$tokens,perl=T))
    lect_types <- c("BE-Du", "NL-Du")
    
    } else {
      clusters_final <- cutree(dend, k=5, order_clusters_as_data = FALSE)
      clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
      clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
      
      }
  
  d.tsv$cluster <- clusters.df[rownames(d.tsv), "cluster"]
  d.tsv$cluster <- as.factor(as.character(d.tsv$cluster))

  set.seed(1990); shape_manual <- sample(c(3,2,16,7,8), length(levels(d.tsv$cluster)))
  set.seed(1990); color_manual <- sample(c("firebrick2","limegreen","royalblue2","grey30","gold"), length(levels(d.tsv$cluster)))
  }

         p <- ggplot(d.tsv, aes(model.x,model.y)) +
           geom_point(aes_string(colour=input[[paste0("color_coding_",conceptName)]], 
                                 shape=input[[paste0("shape_coding_",conceptName)]]) + 
                        aes(text=paste("<b>Country</b>: ", d.tsv$country,"|",
                                       "<b>Word</b>: ", d.tsv$lemma,"|",
                                       "<b>Newspaper</b>: ", d.tsv$newspaper,
                                       "</br><b>Token</b>: ", d.tsv$`_id`,
                                       "</br></br><b>Context</b>: ", d.tsv$text
                                       )
                            )
                      ) + 
           scale_color_manual(values = color_manual) +
           scale_shape_manual(values = shape_manual) +
           theme_bw() 
         
         ggplotly(p, tooltip = "text", opacity=0.5) %>%
           layout(hoverlabel = list(bgcolor=c("rgb(255,255,204"), align="left"),
                  xaxis = list(scaleanchor = "y", scaleratio = 1),
                  dragmode =  "select")
         })

```
```{r, anchor = "Table", echo=FALSE}

l <- "appreciation"
d.concept <- d.clust %>% 
  filter(concept == l) %>%
  select('cluster', 'distance_cityblock', 'filter.fisher','filter.llr','filter.power') %>%
  mutate(distance_cityblock*filter.llr,
         distance_cityblock*filter.fisher,
         distance_cityblock*filter.power) %>%
  select(-starts_with('filter'))

d.concept$semantics <- c(
"<ul class='intable'><li><span class='concept'>appreciation</span> (cues: <i>krijgen, verdienen</i>)</li><li>sometimes <i>erkenning</i> as 'juridical recognition'</li></ul>",
"<i>waardering</i> as 'monetary valuation'",
"<span class='concept'>appreciation</span> (often only cue: <i>voor</i>)",
"<ul class='intable'><li><span class='concept'>appreciation</span> (cues: <i>gebrek, internationaal</i>): <i>waardering</i> more as 'esteem, respect', while <i>erkenning</i> more as 'official recognition'</li><li><i>waardering</i> as 'monetary valuation'</li></ul>",
"<i>erkenning</i> as 'juridical recognition (of political entities)'"
)

tableList <- list()
for (cl in 1:5) {
  
  freqs <- d.clust %>% 
    filter(concept == l & cluster == cl) %>%
    select(starts_with('var'))
  
  freqs.m <- matrix(freqs %>% select(-variants), ncol=2)
  freqs.m <- freqs.m[rowSums(is.na(freqs.m)) != ncol(freqs.m), ]
  
  variants <- as.character(freqs$variants)
  
  colnames(freqs.m) <- c("BE","NL")
  rownames(freqs.m) <- str_split(variants,"/")[[1]]
  
  tableList[[cl]] <- kable(freqs.m)
}

d.concept <- d.concept %>% add_column(table=tableList, .before="distance_cityblock")


colnames(d.concept) <- c("Cluster", "Contigency table", "No filter", "LLR filter", "Fisher filter","power filter","Semantics")

kable(d.concept, caption= str_c("Definitions of '", l, "'."), digits = 3, escape = FALSE) %>% 
  kable_styling(full_width = T) %>%
  add_header_above(c("","","City Block"=4,"")) %>%
  column_spec(c(1:7), extra_css = "vertical-align:middle;")
```

## keyboard {#keyboard}
```{r, anchor = "Table", echo=FALSE}

l <- "keyboard"
d.concept <- d.clust %>% 
  filter(concept == l) %>%
  select('cluster', 'distance_cityblock', 'filter.fisher','filter.llr','filter.power') %>%
  mutate(distance_cityblock*filter.llr,
         distance_cityblock*filter.fisher,
         distance_cityblock*filter.power) %>%
  select(-starts_with('filter'))

d.concept$semantics <- c(
"‘key board for computers’ (significant cue: <i>muis</i>)",
"‘key board, most often for computers’ (cues: <i>tokkelen, beeldscherm, computer</i>)",
"shared cue: <i>toetsen</i><ul class='intable'><li><i>klavier</i> as ‘key board, for musical instruments’</li><li><i>toetsenbord</i> as ‘key board, most often for computers'</li><ul>",
"shared cue: <i>achter, zitten</i><ul class='intable'><li><i>klavier</i> as ‘key board, for musical instruments’</li><li><i>toetsenbord</i> as ‘key board, most often for computers'</li><ul>",
"cues: <i>vinger(s), letter(s)</i><ul class='intable'><li><i><i>klavier</i> as ‘key board, for musical instruments’</li><li><i>toetsenbord</i> as ‘key board, most often for computers'</li><ul>"
)

tableList <- list()
for (cl in 1:5) {
  
  freqs <- d.clust %>% 
    filter(concept == l & cluster == cl) %>%
    select(starts_with('var'))
  
  freqs.m <- matrix(freqs %>% select(-variants), ncol=2)
  freqs.m <- freqs.m[rowSums(is.na(freqs.m)) != ncol(freqs.m), ]
  
  variants <- as.character(freqs$variants)
  
  colnames(freqs.m) <- c("BE","NL")
  rownames(freqs.m) <- str_split(variants,"/")[[1]]
  
  tableList[[cl]] <- kable(freqs.m)
}

d.concept <- d.concept %>% add_column(table=tableList, .before="distance_cityblock")


colnames(d.concept) <- c("Cluster", "Contigency table", "No filter", "LLR filter", "Fisher filter","power filter","Semantics")

kable(d.concept, caption= str_c("Definitions of '", l, "'."), digits = 3, escape = FALSE) %>% 
  kable_styling(full_width = T) %>%
  add_header_above(c("","","City Block"=4,"")) %>%
  column_spec(c(1:7), extra_css = "vertical-align:middle;")
```
```{r, keyboard, echo=FALSE}
# change path for retrieving dataframe of semantic nMDS- or tSNE-coordinates and metadata information

conceptName = "keyboard"

# the UI bit:
fluidPage(
        box(status = "primary", solidHeader = TRUE,
        fluidRow(width=4,
            column(width=4, selectInput(inputId = paste0("color_coding_",conceptName),
                        label = "Color coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
            column(width=4, selectInput(inputId = paste0("shape_coding_",conceptName),
                        label = "Shape coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
          )
        # fluidRow(
        #     column(width=12,plotlyOutput("myplot"))
        # )
    )
  )

`+.uneval` <- function(a,b) {
    `class<-`(modifyList(a,b), "uneval")
}

# the server bit:
renderPlotly({
  
  conceptName = "keyboard"

dynamic_method = FALSE
clustering = TRUE
suffix = ".freq3ppmi1"
 
# open and store dataframe

d.tsv <- read.csv(paste0(conceptName,"/",conceptName,".tsne.tsv"),header=T, sep="\t", quote="", check.names = F, encoding="UTF8")

# target token in bold face
d.tsv$`_ctxt.model` <- gsub("<span(<br>|\\s)class='target'>([^<]+)</span>","<b>\\2</b>", d.tsv$`_ctxt.model`)
# significant context words in italics
d.tsv$`_ctxt.model` <- gsub("<u>([^<]+)</u>", "<i>\\1</i>", d.tsv$`_ctxt.model`)
# remove "small font" tags for context words outside of context window
d.tsv$`_ctxt.model` <- gsub("</?small>", "", d.tsv$`_ctxt.model`)
# insert line breaks every 50 characters in the concordance of a token
# (in order to avoid long stretches of text in the visualization)
d.tsv$`_ctxt.model` <- gsub("(.{50,}?)\\s", "\\1<br>", d.tsv$`_ctxt.model`)
d.tsv$text <- d.tsv$`_ctxt.model`

rownames(d.tsv) <- d.tsv$`_id`

if (clustering == TRUE) {
  rows_matrices <- list()
  d <- npyLoad(paste0(conceptName,"/",conceptName,suffix,".ttmx.npy"))
  tokenids <- fromJSON(file = paste0(conceptName,"/",conceptName,suffix,".ttmx.meta"))
  colnames(d) <- tokenids$row_items
  rownames(d) <- tokenids$row_items
  
  dst <- as.dist(as.matrix(d)) # 1000 randomly selected tokens
  
  hcl <- hclust(as.dist(dst), method="ward.D2")
  dend <- as.dendrogram(hcl)
  
  if (dynamic_method == TRUE) {
    clusters <- cutreeDynamic(hcl, distM = dst, method = "tree")
    
    clusters <- clusters[order.dendrogram(dend)]
    clusters_numbers <- unique(clusters) - (0 %in% clusters)
    n_clusters <- length(clusters_numbers)
    
    clusters_final <- cutree(dend, k=n_clusters, order_clusters_as_data = FALSE)
    clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
    clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
    
    variant_types <- unique(gsub("^([^/]+)/.+","\\1",clusters.df$tokens,perl=T))
    lect_types <- c("BE-Du", "NL-Du")
    
    } else {
      clusters_final <- cutree(dend, k=5, order_clusters_as_data = FALSE)
      clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
      clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
      
      }
  
  d.tsv$cluster <- clusters.df[rownames(d.tsv), "cluster"]
  d.tsv$cluster <- as.factor(as.character(d.tsv$cluster))

  set.seed(1990); shape_manual <- sample(c(3,2,16,7,8), length(levels(d.tsv$cluster)))
  set.seed(1990); color_manual <- sample(c("firebrick2","limegreen","royalblue2","grey30","gold"), length(levels(d.tsv$cluster)))
  }

         p <- ggplot(d.tsv, aes(model.x,model.y)) +
           geom_point(aes_string(colour=input[[paste0("color_coding_",conceptName)]], 
                                 shape=input[[paste0("shape_coding_",conceptName)]]) + 
                        aes(text=paste("<b>Country</b>: ", d.tsv$country,"|",
                                       "<b>Word</b>: ", d.tsv$lemma,"|",
                                       "<b>Newspaper</b>: ", d.tsv$newspaper,
                                       "</br><b>Token</b>: ", d.tsv$`_id`,
                                       "</br></br><b>Context</b>: ", d.tsv$text
                                       )
                            )
                      ) + 
           scale_color_manual(values = color_manual) +
           scale_shape_manual(values = shape_manual) +
           theme_bw() 
         
         ggplotly(p, tooltip = "text", opacity=0.5) %>%
           layout(hoverlabel = list(bgcolor=c("rgb(255,255,204"), align="left"),
                  xaxis = list(scaleanchor = "y", scaleratio = 1),
                  dragmode =  "select")
         })

```

## chat {#chat}
```{r, anchor = "Table", echo=FALSE}

l <- "chat"
d.concept <- d.clust %>% 
  filter(concept == l) %>%
  select('cluster', 'distance_cityblock', 'filter.fisher','filter.llr','filter.power') %>%
  mutate(distance_cityblock*filter.llr,
         distance_cityblock*filter.fisher,
         distance_cityblock*filter.power) %>%
  select(-starts_with('filter'))

d.concept$semantics <- c(
"<span class='concept'>chat</span>, more specifically in the phrase <i>‘een babbeltje/praatje <b>maken</b>’</i>",
"<span class='concept'>chat</span>, more specifically in the phrase <i>‘een babbel/babbeltje/praatje <b>slaan</b>’</i>",
"<ul class='intable'><li><i>babbel</i> as ‘a smooth way of talking ’, more specifically in the phrase <i>‘vlotte babbel’</i></li><li><span class='concept'>chat</span>, more specifically in the phrase <i>‘een babbel/babbeltje/(praatje) <b>doen met</b>’</i></li></ul>",
"<i>praatje</i> as ‘informal talk’ (<i>‘een praatje houden’</i>)",
"<ul class='intable'><li><span class='concept'>chat</span>: <i>een gezellig(e) babbel/praatje, een praatje/babbel maken </i>etc.</li><li><i>praatje(s)</i> as ‘misleading/persuasive talk’ or ‘informal talk’</li></ul>"
)

tableList <- list()
for (cl in 1:5) {
  
  freqs <- d.clust %>% 
    filter(concept == l & cluster == cl) %>%
    select(starts_with('var'))
  
  freqs.m <- matrix(freqs %>% select(-variants), ncol=2)
  
  variants <- as.character(freqs$variants)
  
  colnames(freqs.m) <- c("BE","NL")
  rownames(freqs.m) <- str_split(variants,"/")[[1]]
  
  tableList[[cl]] <- kable(freqs.m)
}

d.concept <- d.concept %>% add_column(table=tableList, .before="distance_cityblock")


colnames(d.concept) <- c("Cluster", "Contigency table", "No filter", "LLR filter", "Fisher filter","power filter","Semantics")

kable(d.concept, caption= str_c("Definitions of '", l, "'."), digits = 3, escape = FALSE) %>% 
  kable_styling(full_width = T) %>%
  add_header_above(c("","","City Block"=4,"")) %>%
  column_spec(c(1:7), extra_css = "vertical-align:middle;")
```
```{r, chat, echo=FALSE}
# change path for retrieving dataframe of semantic nMDS- or tSNE-coordinates and metadata information

conceptName = "chat"

# the UI bit:
fluidPage(
        box(status = "primary", solidHeader = TRUE,
        fluidRow(width=4,
            column(width=4, selectInput(inputId = paste0("color_coding_",conceptName),
                        label = "Color coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
            column(width=4, selectInput(inputId = paste0("shape_coding_",conceptName),
                        label = "Shape coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
          )
        # fluidRow(
        #     column(width=12,plotlyOutput("myplot"))
        # )
    )
  )

`+.uneval` <- function(a,b) {
    `class<-`(modifyList(a,b), "uneval")
}

# the server bit:
renderPlotly({
  
  conceptName = "chat"

dynamic_method = FALSE
clustering = TRUE
suffix = ".freq3ppmi1"
 
# open and store dataframe

d.tsv <- read.csv(paste0(conceptName,"/",conceptName,".tsne.tsv"),header=T, sep="\t", quote="", check.names = F, encoding="UTF8")

# target token in bold face
d.tsv$`_ctxt.model` <- gsub("<span(<br>|\\s)class='target'>([^<]+)</span>","<b>\\2</b>", d.tsv$`_ctxt.model`)
# significant context words in italics
d.tsv$`_ctxt.model` <- gsub("<u>([^<]+)</u>", "<i>\\1</i>", d.tsv$`_ctxt.model`)
# remove "small font" tags for context words outside of context window
d.tsv$`_ctxt.model` <- gsub("</?small>", "", d.tsv$`_ctxt.model`)
# insert line breaks every 50 characters in the concordance of a token
# (in order to avoid long stretches of text in the visualization)
d.tsv$`_ctxt.model` <- gsub("(.{50,}?)\\s", "\\1<br>", d.tsv$`_ctxt.model`)
d.tsv$text <- d.tsv$`_ctxt.model`

rownames(d.tsv) <- d.tsv$`_id`

if (clustering == TRUE) {
  rows_matrices <- list()
  d <- npyLoad(paste0(conceptName,"/",conceptName,suffix,".ttmx.npy"))
  tokenids <- fromJSON(file = paste0(conceptName,"/",conceptName,suffix,".ttmx.meta"))
  colnames(d) <- tokenids$row_items
  rownames(d) <- tokenids$row_items
  
  dst <- as.dist(as.matrix(d)) # 1000 randomly selected tokens
  
  hcl <- hclust(as.dist(dst), method="ward.D2")
  dend <- as.dendrogram(hcl)
  
  if (dynamic_method == TRUE) {
    clusters <- cutreeDynamic(hcl, distM = dst, method = "tree")
    
    clusters <- clusters[order.dendrogram(dend)]
    clusters_numbers <- unique(clusters) - (0 %in% clusters)
    n_clusters <- length(clusters_numbers)
    
    clusters_final <- cutree(dend, k=n_clusters, order_clusters_as_data = FALSE)
    clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
    clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
    
    variant_types <- unique(gsub("^([^/]+)/.+","\\1",clusters.df$tokens,perl=T))
    lect_types <- c("BE-Du", "NL-Du")
    
    } else {
      clusters_final <- cutree(dend, k=5, order_clusters_as_data = FALSE)
      clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
      clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
      
      }
  
  d.tsv$cluster <- clusters.df[rownames(d.tsv), "cluster"]
  d.tsv$cluster <- as.factor(as.character(d.tsv$cluster))

  set.seed(1990); shape_manual <- sample(c(3,2,16,7,8), length(levels(d.tsv$cluster)))
  set.seed(1990); color_manual <- sample(c("firebrick2","limegreen","royalblue2","grey30","gold"), length(levels(d.tsv$cluster)))
  }

         p <- ggplot(d.tsv, aes(model.x,model.y)) +
           geom_point(aes_string(colour=input[[paste0("color_coding_",conceptName)]], 
                                 shape=input[[paste0("shape_coding_",conceptName)]]) + 
                        aes(text=paste("<b>Country</b>: ", d.tsv$country,"|",
                                       "<b>Word</b>: ", d.tsv$lemma,"|",
                                       "<b>Newspaper</b>: ", d.tsv$newspaper,
                                       "</br><b>Token</b>: ", d.tsv$`_id`,
                                       "</br></br><b>Context</b>: ", d.tsv$text
                                       )
                            )
                      ) + 
           scale_color_manual(values = color_manual) +
           scale_shape_manual(values = shape_manual) +
           theme_bw() 
         
         ggplotly(p, tooltip = "text", opacity=0.5) %>%
           layout(hoverlabel = list(bgcolor=c("rgb(255,255,204"), align="left"),
                  xaxis = list(scaleanchor = "y", scaleratio = 1),
                  dragmode =  "select")
         })

```

## opening hours {#openinghours}
```{r, anchor = "Table", echo=FALSE}

l <- "opening_hours"
d.concept <- d.clust %>% 
  filter(concept == l) %>%
  select('cluster', 'distance_cityblock', 'filter.fisher','filter.llr','filter.power') %>%
  mutate(distance_cityblock*filter.llr,
         distance_cityblock*filter.fisher,
         distance_cityblock*filter.power) %>%
  select(-starts_with('filter'))

d.concept$semantics <- c(
"<ul class='intable'><li><span class='concept'>opening hours<span></li><li>sometimes <i>openingsuur/openingstijd</i> as 'moment in which a business opens'</li></ul>",
"<span class='concept'>opening hours<span> (cues: <i>flexibel, langer, beperkt, aanpassen, versoepelen, terugschroeven</i>)",
"<span class='concept'>opening hours<span> (cues: <i>verruiming, ruim</i>)",
"<span class='concept'>opening hours<span> (cues: hours, days)",
"<span class='concept'>opening hours<span> (cues: <i>tijdens</i>)"
)

tableList <- list()
for (cl in 1:5) {
  
  freqs <- d.clust %>% 
    filter(concept == l & cluster == cl) %>%
    select(starts_with('var'))
  
  freqs.m <- matrix(freqs %>% select(-variants), ncol=2)
  freqs.m <- freqs.m[rowSums(is.na(freqs.m)) != ncol(freqs.m), ]
  
  variants <- as.character(freqs$variants)
  
  colnames(freqs.m) <- c("BE","NL")
  rownames(freqs.m) <- str_split(variants,"/")[[1]]
  
  tableList[[cl]] <- kable(freqs.m)
}

d.concept <- d.concept %>% add_column(table=tableList, .before="distance_cityblock")


colnames(d.concept) <- c("Cluster", "Contigency table", "No filter", "LLR filter", "Fisher filter","power filter","Semantics")

kable(d.concept, caption= str_c("Definitions of '", l, "'."), digits = 3, escape = FALSE) %>% 
  kable_styling(full_width = T) %>%
  add_header_above(c("","","City Block"=4,"")) %>%
  column_spec(c(1:7), extra_css = "vertical-align:middle;")
```
```{r, opening_hours, echo=FALSE}
# change path for retrieving dataframe of semantic nMDS- or tSNE-coordinates and metadata information

conceptName = "opening_hours"

# the UI bit:
fluidPage(
        box(status = "primary", solidHeader = TRUE,
        fluidRow(width=4,
            column(width=4, selectInput(inputId = paste0("color_coding_",conceptName),
                        label = "Color coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
            column(width=4, selectInput(inputId = paste0("shape_coding_",conceptName),
                        label = "Shape coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
          )
        # fluidRow(
        #     column(width=12,plotlyOutput("myplot"))
        # )
    )
  )

`+.uneval` <- function(a,b) {
    `class<-`(modifyList(a,b), "uneval")
}

# the server bit:
renderPlotly({
  
  conceptName = "opening_hours"

dynamic_method = FALSE
clustering = TRUE
suffix = ".freq3ppmi1"
 
# open and store dataframe

d.tsv <- read.csv(paste0(conceptName,"/",conceptName,".tsne.tsv"),header=T, sep="\t", quote="", check.names = F, encoding="UTF8")

# target token in bold face
d.tsv$`_ctxt.model` <- gsub("<span(<br>|\\s)class='target'>([^<]+)</span>","<b>\\2</b>", d.tsv$`_ctxt.model`)
# significant context words in italics
d.tsv$`_ctxt.model` <- gsub("<u>([^<]+)</u>", "<i>\\1</i>", d.tsv$`_ctxt.model`)
# remove "small font" tags for context words outside of context window
d.tsv$`_ctxt.model` <- gsub("</?small>", "", d.tsv$`_ctxt.model`)
# insert line breaks every 50 characters in the concordance of a token
# (in order to avoid long stretches of text in the visualization)
d.tsv$`_ctxt.model` <- gsub("(.{50,}?)\\s", "\\1<br>", d.tsv$`_ctxt.model`)
d.tsv$text <- d.tsv$`_ctxt.model`

rownames(d.tsv) <- d.tsv$`_id`

if (clustering == TRUE) {
  rows_matrices <- list()
  d <- npyLoad(paste0(conceptName,"/",conceptName,suffix,".ttmx.npy"))
  tokenids <- fromJSON(file = paste0(conceptName,"/",conceptName,suffix,".ttmx.meta"))
  colnames(d) <- tokenids$row_items
  rownames(d) <- tokenids$row_items
  
  dst <- as.dist(as.matrix(d)) # 1000 randomly selected tokens
  
  hcl <- hclust(as.dist(dst), method="ward.D2")
  dend <- as.dendrogram(hcl)
  
  if (dynamic_method == TRUE) {
    clusters <- cutreeDynamic(hcl, distM = dst, method = "tree")
    
    clusters <- clusters[order.dendrogram(dend)]
    clusters_numbers <- unique(clusters) - (0 %in% clusters)
    n_clusters <- length(clusters_numbers)
    
    clusters_final <- cutree(dend, k=n_clusters, order_clusters_as_data = FALSE)
    clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
    clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
    
    variant_types <- unique(gsub("^([^/]+)/.+","\\1",clusters.df$tokens,perl=T))
    lect_types <- c("BE-Du", "NL-Du")
    
    } else {
      clusters_final <- cutree(dend, k=5, order_clusters_as_data = FALSE)
      clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
      clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
      
      }
  
  d.tsv$cluster <- clusters.df[rownames(d.tsv), "cluster"]
  d.tsv$cluster <- as.factor(as.character(d.tsv$cluster))

  set.seed(1990); shape_manual <- sample(c(3,2,16,7,8), length(levels(d.tsv$cluster)))
  set.seed(1990); color_manual <- sample(c("firebrick2","limegreen","royalblue2","grey30","gold"), length(levels(d.tsv$cluster)))
  }

         p <- ggplot(d.tsv, aes(model.x,model.y)) +
           geom_point(aes_string(colour=input[[paste0("color_coding_",conceptName)]], 
                                 shape=input[[paste0("shape_coding_",conceptName)]]) + 
                        aes(text=paste("<b>Country</b>: ", d.tsv$country,"|",
                                       "<b>Word</b>: ", d.tsv$lemma,"|",
                                       "<b>Newspaper</b>: ", d.tsv$newspaper,
                                       "</br><b>Token</b>: ", d.tsv$`_id`,
                                       "</br></br><b>Context</b>: ", d.tsv$text
                                       )
                            )
                      ) + 
           scale_color_manual(values = color_manual) +
           scale_shape_manual(values = shape_manual) +
           theme_bw() 
         
         ggplotly(p, tooltip = "text", opacity=0.5) %>%
           layout(hoverlabel = list(bgcolor=c("rgb(255,255,204"), align="left"),
                  xaxis = list(scaleanchor = "y", scaleratio = 1),
                  dragmode =  "select")
         })

```

## dip {#dip}
```{r, anchor = "Table", echo=FALSE}

l <- "dip"
d.concept <- d.clust %>% 
  filter(concept == l) %>%
  select('cluster', 'distance_cityblock', 'filter.fisher','filter.llr','filter.power') %>%
  mutate(distance_cityblock*filter.llr,
         distance_cityblock*filter.fisher,
         distance_cityblock*filter.power) %>%
  select(-starts_with('filter'))

d.concept$semantics <- c(
"<ul class='intable'><li><i>dip</i> in the fixed phrase <i>‘double dip’</i></li><li>‘economic recession’ (shared cues: <i>economisch, conjunctureel</i>)</li><li>sometimes <i>inzinking</i> as ‘mental/physical breakdown’</li></ul>",
"<i>dip</i> in the phrase <i>‘in een dip zitten’</i>",
"different types of <span class='concept'>dip</span> (mental/physical/economic) with strong cue <i>tijdelijk</i>",
"different types of <span class='concept'>dip</span> (mental/physical/economic) with strong cue <i>na</i>",
"different types of <span class='concept'>dip</span> (mental/physical/economic) with strong cue <i>herstellen, kennen, klein</i>")

tableList <- list()
for (cl in 1:5) {
  
  freqs <- d.clust %>% 
    filter(concept == l & cluster == cl) %>%
    select(starts_with('var'))
  
  freqs.m <- matrix(freqs %>% select(-variants), ncol=2)
  freqs.m <- freqs.m[rowSums(is.na(freqs.m)) != ncol(freqs.m), ]
  
  variants <- as.character(freqs$variants)
  
  colnames(freqs.m) <- c("BE","NL")
  rownames(freqs.m) <- str_split(variants,"/")[[1]]
  
  tableList[[cl]] <- kable(freqs.m)
}

d.concept <- d.concept %>% add_column(table=tableList, .before="distance_cityblock")


colnames(d.concept) <- c("Cluster", "Contigency table", "No filter", "LLR filter", "Fisher filter","power filter","Semantics")

kable(d.concept, caption= str_c("Definitions of '", l, "'."), digits = 3, escape = FALSE) %>% 
  kable_styling(full_width = T) %>%
  add_header_above(c("","","City Block"=4,"")) %>%
  column_spec(c(1:7), extra_css = "vertical-align:middle;")
```
```{r, dip, echo=FALSE}
# change path for retrieving dataframe of semantic nMDS- or tSNE-coordinates and metadata information

conceptName = "dip"

# the UI bit:
fluidPage(
        box(status = "primary", solidHeader = TRUE,
        fluidRow(width=4,
            column(width=4, selectInput(inputId = paste0("color_coding_",conceptName),
                        label = "Color coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
            column(width=4, selectInput(inputId = paste0("shape_coding_",conceptName),
                        label = "Shape coding:",
                        choices = c("cluster","lemma","country"),
                        multiple = TRUE)),
          )
        # fluidRow(
        #     column(width=12,plotlyOutput("myplot"))
        # )
    )
  )

`+.uneval` <- function(a,b) {
    `class<-`(modifyList(a,b), "uneval")
}

# the server bit:
renderPlotly({
  
  conceptName = "dip"

dynamic_method = FALSE
clustering = TRUE
suffix = ".freq3ppmi1"
 
# open and store dataframe

d.tsv <- read.csv(paste0(conceptName,"/",conceptName,".tsne.tsv"),header=T, sep="\t", quote="", check.names = F, encoding="UTF8")

# target token in bold face
d.tsv$`_ctxt.model` <- gsub("<span(<br>|\\s)class='target'>([^<]+)</span>","<b>\\2</b>", d.tsv$`_ctxt.model`)
# significant context words in italics
d.tsv$`_ctxt.model` <- gsub("<u>([^<]+)</u>", "<i>\\1</i>", d.tsv$`_ctxt.model`)
# remove "small font" tags for context words outside of context window
d.tsv$`_ctxt.model` <- gsub("</?small>", "", d.tsv$`_ctxt.model`)
# insert line breaks every 50 characters in the concordance of a token
# (in order to avoid long stretches of text in the visualization)
d.tsv$`_ctxt.model` <- gsub("(.{50,}?)\\s", "\\1<br>", d.tsv$`_ctxt.model`)
d.tsv$text <- d.tsv$`_ctxt.model`

rownames(d.tsv) <- d.tsv$`_id`

if (clustering == TRUE) {
  rows_matrices <- list()
  d <- npyLoad(paste0(conceptName,"/",conceptName,suffix,".ttmx.npy"))
  tokenids <- fromJSON(file = paste0(conceptName,"/",conceptName,suffix,".ttmx.meta"))
  colnames(d) <- tokenids$row_items
  rownames(d) <- tokenids$row_items
  
  dst <- as.dist(as.matrix(d)) # 1000 randomly selected tokens
  
  hcl <- hclust(as.dist(dst), method="ward.D2")
  dend <- as.dendrogram(hcl)
  
  if (dynamic_method == TRUE) {
    clusters <- cutreeDynamic(hcl, distM = dst, method = "tree")
    
    clusters <- clusters[order.dendrogram(dend)]
    clusters_numbers <- unique(clusters) - (0 %in% clusters)
    n_clusters <- length(clusters_numbers)
    
    clusters_final <- cutree(dend, k=n_clusters, order_clusters_as_data = FALSE)
    clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
    clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
    
    variant_types <- unique(gsub("^([^/]+)/.+","\\1",clusters.df$tokens,perl=T))
    lect_types <- c("BE-Du", "NL-Du")
    
    } else {
      clusters_final <- cutree(dend, k=5, order_clusters_as_data = FALSE)
      clusters.df <- data.frame(tokens=names(clusters_final),cluster=clusters_final)
      clusters.df$cluster <- as.factor(as.character(clusters.df$cluster))
      
      }
  
  d.tsv$cluster <- clusters.df[rownames(d.tsv), "cluster"]
  d.tsv$cluster <- as.factor(as.character(d.tsv$cluster))

  set.seed(1990); shape_manual <- sample(c(3,2,16,7,8), length(levels(d.tsv$cluster)))
  set.seed(1990); color_manual <- sample(c("firebrick2","limegreen","royalblue2","grey30","gold"), length(levels(d.tsv$cluster)))
  }

         p <- ggplot(d.tsv, aes(model.x,model.y)) +
           geom_point(aes_string(colour=input[[paste0("color_coding_",conceptName)]], 
                                 shape=input[[paste0("shape_coding_",conceptName)]]) + 
                        aes(text=paste("<b>Country</b>: ", d.tsv$country,"|",
                                       "<b>Word</b>: ", d.tsv$lemma,"|",
                                       "<b>Newspaper</b>: ", d.tsv$newspaper,
                                       "</br><b>Token</b>: ", d.tsv$`_id`,
                                       "</br></br><b>Context</b>: ", d.tsv$text
                                       )
                            )
                      ) + 
           scale_color_manual(values = color_manual) +
           scale_shape_manual(values = shape_manual) +
           theme_bw() 
         
         ggplotly(p, tooltip = "text", opacity=0.5) %>%
           layout(hoverlabel = list(bgcolor=c("rgb(255,255,204"), align="left"),
                  xaxis = list(scaleanchor = "y", scaleratio = 1),
                  dragmode =  "select")
         })

```



Some other text to show here